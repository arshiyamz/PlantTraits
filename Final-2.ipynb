{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2ec958-e790-4efe-974f-7d381d599d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1dc637f470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "from torchvision.models.convnext import LayerNorm2d\n",
    "import csv\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc588b03-4aef-4568-ab1f-0822c2afe8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510a6fb8-651b-4a6b-afda-9e254143376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.genfromtxt('/root/ml/data/train.csv', dtype=float, delimiter=',', skip_header=1)\n",
    "all_dataint = np.genfromtxt('/root/ml/data/train.csv', dtype=int, delimiter=',', skip_header=1)\n",
    "all_test = np.genfromtxt('/root/ml/data/test.csv', dtype=float, delimiter=',', skip_header=1)\n",
    "all_testint = np.genfromtxt('/root/ml/data/test.csv', dtype=int, delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6418c95-b818-41fa-ac63-24533509bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.v2.Compose([\n",
    "    transforms.v2.RandomApply([\n",
    "        transforms.v2.RandomOrder([\n",
    "            transforms.v2.AutoAugment(\n",
    "                policy=transforms.v2.AutoAugmentPolicy.IMAGENET,\n",
    "                interpolation=transforms.v2.InterpolationMode.BILINEAR\n",
    "            ),\n",
    "            transforms.v2.RandAugment(),\n",
    "            transforms.v2.TrivialAugmentWide()  \n",
    "        ])],\n",
    "        p = 1.0\n",
    "    ),\n",
    "    transforms.v2.ToImage(),\n",
    "    transforms.v2.ToDtype(torch.float32, scale=True),\n",
    "    transforms.v2.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcaeabc2-45ca-48de-807d-fa30e4e2441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  '''\n",
    "  Prepare the dataset for regression\n",
    "  '''\n",
    "\n",
    "  def __init__(self, images, X, y, ids, scale_data=True, random=True):\n",
    "      if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "        # Apply scaling if necessary\n",
    "        if scale_data:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.ids = ids\n",
    "        #self.y = torch.log(torch.from_numpy(y))\n",
    "        self.y = torch.from_numpy(y).cuda()\n",
    "        self.images = images\n",
    "      self.random = random\n",
    "      self.transform = torchvision.transforms.Compose([\n",
    "        transforms.v2.ToImage(),\n",
    "        transforms.v2.ToDtype(torch.float32, scale=True),\n",
    "        transforms.v2.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "      ])\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "      #img_path = os.path.join(self.path, f'{str(self.ids[i].item())}.jpeg')\n",
    "      #image = self.transform(read_image(img_path).float())\n",
    "      image = self.images[self.ids[i]]\n",
    "      if self.random:\n",
    "          image = transform(image)\n",
    "      else:\n",
    "          image = self.transform(image)\n",
    "      #image = pretrained_transforms_test(read_image(img_path).half())\n",
    "      return self.X[i], image, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4eaca72-62cf-43b2-96c2-b52795e129cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "  '''\n",
    "  Prepare the dataset for regression\n",
    "  '''\n",
    "\n",
    "  def __init__(self, images, X, ids, scale_data=True):\n",
    "      if not torch.is_tensor(X):\n",
    "        # Apply scaling if necessary\n",
    "        if scale_data:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.ids = ids\n",
    "      self.images = images\n",
    "      self.transform = transforms.Compose([\n",
    "        transforms.v2.ToImage(),\n",
    "        transforms.v2.ToDtype(torch.float32, scale=True),\n",
    "        transforms.v2.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "      ])\n",
    "  def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "      #img_path = os.path.join(self.path, f'{str(self.ids[i].item())}.jpeg')\n",
    "      #image = self.transform(read_image(img_path).float())\n",
    "      image = self.transform(self.images[self.ids[i]])\n",
    "      return self.X[i], image, self.ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5980fb68-ae82-4c30-8525-c766cb482989",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = all_dataint[:, 0]\n",
    "X = all_data[:, 1:-6]\n",
    "Y = all_data[:, -6:]\n",
    "\n",
    "X_train, X_val, Y_train, Y_val, ids_train, ids_val = train_test_split(X, Y, ids, test_size=0.10, random_state=42)\n",
    "\n",
    "Y_means = torch.mean(torch.from_numpy(Y_train), 0).cuda()\n",
    "Y_stds = torch.std(torch.from_numpy(Y_train), 0).cuda()\n",
    "#X_means = torch.mean(torch.from_numpy(X_train), 0).cuda()\n",
    "#X_stds = torch.std(torch.from_numpy(X_train), 0).cuda()\n",
    "\n",
    "ids_test = all_testint[:, 0]\n",
    "X_test = all_test[:, 1:]\n",
    "\n",
    "batchsize = 64\n",
    "\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#])\n",
    "\n",
    "#trainimages = torchvision.datasets.ImageFolder(root=\"/root/ml/data/train_images/\", transform=transform)\n",
    "#testimages = torchvision.datasets.ImageFolder(root=\"/root/ml/data/test_images/\", transform=transform)\n",
    "\n",
    "#fulldataset = Dataset('/root/ml/data/train_images/', X, Y, ids)\n",
    "#traindataset, valdataset = torch.utils.data.random_split(fulldataset, [0.8, 0.2])\n",
    "trainimages = dict()\n",
    "for i in ids_train:\n",
    "    img_path = os.path.join('/root/ml/data/train_images/', f'{i}.jpeg')\n",
    "    trainimages[i] = Image.open(img_path)\n",
    "traindatasetaug = Dataset(trainimages, X_train, Y_train, ids_train, random = True)\n",
    "traindataset = Dataset(trainimages, X_train, Y_train, ids_train, random = False)\n",
    "\n",
    "valimages = dict()\n",
    "for i in ids_val:\n",
    "    img_path = os.path.join('/root/ml/data/train_images/', f'{i}.jpeg')\n",
    "    valimages[i] = Image.open(img_path)\n",
    "valdataset = Dataset(valimages, X_val, Y_val, ids_val, random = False)\n",
    "\n",
    "trainfulldataset = torch.utils.data.ConcatDataset([traindatasetaug, traindataset])\n",
    "trainloader = torch.utils.data.DataLoader(trainfulldataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "valloader = torch.utils.data.DataLoader(valdataset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "testimages = dict()\n",
    "for i in ids_test:\n",
    "    img_path = os.path.join('/root/ml/data/test_images/', f'{i}.jpeg')\n",
    "    testimages[i] = Image.open(img_path)\n",
    "testdataset = TestDataset(testimages, X_test, ids_test)\n",
    "testloader = torch.utils.data.DataLoader(testdataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "623bfd44-6530-4e3f-9980-c9395edc53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualMLPScalars(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self, num_inputs = 163, num_outputs = 1024):\n",
    "    super().__init__()\n",
    "    self.num_inputs = num_inputs\n",
    "    self.num_outputs = num_outputs\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Linear(num_inputs, 512),\n",
    "      nn.LeakyReLU()\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Linear(512, 1024),\n",
    "      nn.LayerNorm(1024),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Linear(1024, 1024),\n",
    "      nn.LeakyReLU()\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Linear(1024, 512),\n",
    "      nn.LeakyReLU()\n",
    "    )\n",
    "    self.layer5 = nn.Sequential(\n",
    "      nn.Linear(512, 512),\n",
    "      nn.LayerNorm(512),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.layer6 = nn.Sequential(\n",
    "      nn.Linear(512, 256),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.layer7 = nn.Sequential(\n",
    "      nn.Linear(256, 128),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, X):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    output1 = self.layer1(X)\n",
    "    output2 = self.layer2(output1)\n",
    "    output3 = self.layer3(output2) + output2\n",
    "    output4 = self.layer4(output3)\n",
    "    output5 = self.layer5(output4) + output4\n",
    "    output6 = self.layer6(output5)\n",
    "    output = self.layer7(output6)\n",
    "    return output\n",
    "\n",
    "class ResidualMLPFC(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self, num_inputs = 2048, num_outputs = 6):\n",
    "    super().__init__()\n",
    "    self.num_inputs = num_inputs\n",
    "    self.num_outputs = num_outputs\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Linear(num_inputs, 512),\n",
    "      nn.LeakyReLU(inplace=True)\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Linear(512, 512),\n",
    "      nn.LayerNorm(512),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Linear(512, 128),\n",
    "      nn.LeakyReLU(inplace=True)\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Linear(128, 64),\n",
    "      nn.LayerNorm(64),\n",
    "      nn.LeakyReLU(inplace=True)\n",
    "    )\n",
    "    self.layer5 = nn.Sequential(\n",
    "      nn.Linear(64, 6),\n",
    "    )\n",
    "\n",
    "  def forward(self, X):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    output1 = self.layer1(X)\n",
    "    output2 = self.layer2(output1) + output1\n",
    "    output3 = self.layer3(output2)\n",
    "    output4 = self.layer4(output3)\n",
    "    output5 = self.layer5(output4)\n",
    "    return output5 * Y_stds + Y_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3528b03-ba99-4efe-a117-24a993c6f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoolModel(nn.Module):\n",
    "  '''\n",
    "    My cool model for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    '''\n",
    "    self.image_net = torchvision.models.resnet152(weights='DEFAULT')\n",
    "    #for param in self.image_net.parameters():\n",
    "    #    param.requires_grad = False\n",
    "    num_features = self.image_net.fc.in_features\n",
    "    #print(num_features)\n",
    "    #self.image_net.fc = nn.Sequential(\n",
    "    #    nn.Linear(num_features, 1024)\n",
    "    #)\n",
    "    self.image_net.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.LayerNorm(512),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(512, 256)\n",
    "    )\n",
    "    '''\n",
    "    '''\n",
    "    self.image_net = torchvision.models.swin_v2_b(weights='DEFAULT')\n",
    "    num_features = self.image_net.head.in_features\n",
    "    self.image_net.head = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.LayerNorm(512),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256)\n",
    "    )\n",
    "    '''\n",
    "    self.image_net = torchvision.models.convnext_large(weights='DEFAULT')\n",
    "    n_inputs = None\n",
    "    for name, child in self.image_net.named_children():\n",
    "        if name == 'classifier':\n",
    "            for sub_name, sub_child in child.named_children():\n",
    "                if sub_name == '2':\n",
    "                    n_inputs = sub_child.in_features\n",
    "    n_outputs = 256\n",
    "    sequential_layers = nn.Sequential(\n",
    "        LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True),\n",
    "        nn.Flatten(start_dim=1, end_dim=-1),\n",
    "        nn.Linear(n_inputs, 2048, bias=True),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, n_outputs),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    self.image_net.classifier = sequential_layers\n",
    "    \n",
    "    \n",
    "    self.scalar_net = ResidualMLPScalars()\n",
    "    self.fc = ResidualMLPFC(256 + 128, 6)\n",
    "    \n",
    "  def forward(self, image, scalars):\n",
    "    resnet_out = self.image_net(image)\n",
    "    #return resnet_out\n",
    "    scalar_out = self.scalar_net(scalars)\n",
    "    results = self.fc(torch.cat((resnet_out, scalar_out), 1))\n",
    "    #resnet_out = self.downsample_layer(resnet_out)\n",
    "    #results = self.fc(torch.cat((resnet_out, scalars), 1))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4bb64dd-b82c-481b-8db3-d92c3df1e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610cb931-152f-4138-9ea9-f469b1f8e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateR2(guess, labels, means):\n",
    "    SS_tot = torch.sum((labels - means) ** 2, 0)\n",
    "    SS_res = torch.sum((guess - labels) ** 2, 0)\n",
    "    return torch.mean(1 - (SS_res / SS_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f530b95c-c4c9-4b91-ae90-79d9bdf48d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = torchvision.models.convnext_large(weights='DEFAULT')\n",
    "\n",
    "n_inputs = None\n",
    "for name, child in model.named_children():\n",
    "    if name == 'classifier':\n",
    "        for sub_name, sub_child in child.named_children():\n",
    "            if sub_name == '2':\n",
    "                n_inputs = sub_child.in_features\n",
    "n_outputs = 6\n",
    "\n",
    "sequential_layers = nn.Sequential(\n",
    "    LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(n_inputs, 2048, bias=True),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2048, n_outputs)\n",
    ")\n",
    "model.classifier = sequential_layers\n",
    "\n",
    "model = model.cuda()\n",
    "'''\n",
    "model = MyCoolModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b4ae09-dbd4-499b-bb72-72e2e898edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLP()\n",
    "#vgg11 = VGG11().cuda()\n",
    "#vgg11 = torch.load('./VGG11-RUN-1-EPOCH-2')\n",
    "#vgg11 = torch.load('./VGG11-MLP-BLANCEDMSE-EPOCH-6')\n",
    "\n",
    "def BalancedMSELoss(output, target):\n",
    "    loss = torch.sum(((output - target) / Y_stds)**2)\n",
    "    return loss\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.MSELoss()\n",
    "loss_function = BalancedMSELoss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "#optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad705032-a8d1-4892-a115-4f74b38be9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 4.228468\n",
      "Loss after mini-batch    20: 4.741458\n",
      "Loss after mini-batch    30: 4.298169\n",
      "Loss after mini-batch    40: 4.288399\n",
      "Loss after mini-batch    50: 4.435717\n",
      "Loss after mini-batch    60: 3.907275\n",
      "Loss after mini-batch    70: 3.774861\n",
      "Loss after mini-batch    80: 3.984678\n",
      "Loss after mini-batch    90: 4.848957\n",
      "Loss after mini-batch   100: 3.966998\n",
      "Loss after mini-batch   110: 4.264110\n",
      "Loss after mini-batch   120: 4.431697\n",
      "Loss after mini-batch   130: 4.205693\n",
      "Loss after mini-batch   140: 4.301761\n",
      "Loss after mini-batch   150: 3.722799\n",
      "Loss after mini-batch   160: 4.118874\n",
      "Loss after mini-batch   170: 4.583405\n",
      "Loss after mini-batch   180: 4.501888\n",
      "Loss after mini-batch   190: 4.149472\n",
      "Loss after mini-batch   200: 4.324503\n",
      "Loss after mini-batch   210: 4.403068\n",
      "Loss after mini-batch   220: 4.431045\n",
      "Loss after mini-batch   230: 4.192840\n",
      "Loss after mini-batch   240: 4.101342\n",
      "Loss after mini-batch   250: 4.366985\n",
      "Loss after mini-batch   260: 4.501255\n",
      "Loss after mini-batch   270: 4.351505\n",
      "Loss after mini-batch   280: 4.165888\n",
      "Loss after mini-batch   290: 3.801162\n",
      "Loss after mini-batch   300: 4.072377\n",
      "Loss after mini-batch   310: 3.913597\n",
      "Loss after mini-batch   320: 4.151746\n",
      "Loss after mini-batch   330: 3.912778\n",
      "Loss after mini-batch   340: 3.966812\n",
      "Loss after mini-batch   350: 4.538056\n",
      "Loss after mini-batch   360: 4.067311\n",
      "Loss after mini-batch   370: 4.784529\n",
      "Loss after mini-batch   380: 4.142380\n",
      "Loss after mini-batch   390: 4.401605\n",
      "Loss after mini-batch   400: 3.943830\n",
      "Loss after mini-batch   410: 4.044512\n",
      "Loss after mini-batch   420: 4.300477\n",
      "Loss after mini-batch   430: 4.363021\n",
      "Loss after mini-batch   440: 4.478413\n",
      "Loss after mini-batch   450: 4.139075\n",
      "Loss after mini-batch   460: 4.136899\n",
      "Loss after mini-batch   470: 4.062021\n",
      "Loss after mini-batch   480: 3.925216\n",
      "Loss after mini-batch   490: 3.887761\n",
      "Loss after mini-batch   500: 4.501270\n",
      "Loss after mini-batch   510: 4.154071\n",
      "Loss after mini-batch   520: 4.587439\n",
      "Loss after mini-batch   530: 4.190434\n",
      "Loss after mini-batch   540: 4.433849\n",
      "Loss after mini-batch   550: 4.060278\n",
      "Loss after mini-batch   560: 4.182755\n",
      "Loss after mini-batch   570: 4.010669\n",
      "Loss after mini-batch   580: 4.369131\n",
      "Loss after mini-batch   590: 4.226202\n",
      "Loss after mini-batch   600: 4.086188\n",
      "Loss after mini-batch   610: 4.175256\n",
      "Loss after mini-batch   620: 4.491588\n",
      "Loss after mini-batch   630: 4.165560\n",
      "Loss after mini-batch   640: 4.241543\n",
      "Loss after mini-batch   650: 3.957114\n",
      "Loss after mini-batch   660: 4.194448\n",
      "Loss after mini-batch   670: 4.745854\n",
      "Loss after mini-batch   680: 3.966136\n",
      "Loss after mini-batch   690: 4.187943\n",
      "Loss after mini-batch   700: 4.314638\n",
      "Loss after mini-batch   710: 3.936457\n",
      "Loss after mini-batch   720: 3.938678\n",
      "Loss after mini-batch   730: 3.946944\n",
      "Loss after mini-batch   740: 3.954856\n",
      "Loss after mini-batch   750: 4.161329\n",
      "Loss after mini-batch   760: 4.039805\n",
      "Loss after mini-batch   770: 4.269723\n",
      "Loss after mini-batch   780: 4.297602\n",
      "Loss after mini-batch   790: 3.809398\n",
      "Loss after mini-batch   800: 3.758563\n",
      "Loss after mini-batch   810: 4.084126\n",
      "Loss after mini-batch   820: 4.118655\n",
      "Loss after mini-batch   830: 4.248931\n",
      "Loss after mini-batch   840: 4.602015\n",
      "Loss after mini-batch   850: 3.874277\n",
      "Loss after mini-batch   860: 4.358695\n",
      "Loss after mini-batch   870: 4.489174\n",
      "Loss after mini-batch   880: 3.980969\n",
      "Loss after mini-batch   890: 4.288839\n",
      "Loss after mini-batch   900: 4.978699\n",
      "Loss after mini-batch   910: 4.156572\n",
      "Loss after mini-batch   920: 4.165047\n",
      "Loss after mini-batch   930: 3.954525\n",
      "Loss after mini-batch   940: 4.381357\n",
      "Loss after mini-batch   950: 4.130349\n",
      "Loss after mini-batch   960: 4.198704\n",
      "Loss after mini-batch   970: 4.060805\n",
      "Loss after mini-batch   980: 4.058845\n",
      "Loss after mini-batch   990: 4.018651\n",
      "Loss after mini-batch  1000: 3.946301\n",
      "Loss after mini-batch  1010: 4.397193\n",
      "Loss after mini-batch  1020: 3.889106\n",
      "Loss after mini-batch  1030: 4.055755\n",
      "Loss after mini-batch  1040: 4.466638\n",
      "Loss after mini-batch  1050: 3.946249\n",
      "Loss after mini-batch  1060: 4.493653\n",
      "Loss after mini-batch  1070: 3.967893\n",
      "Loss after mini-batch  1080: 4.070761\n",
      "Loss after mini-batch  1090: 4.210982\n",
      "Loss after mini-batch  1100: 4.124224\n",
      "Loss after mini-batch  1110: 4.032309\n",
      "Loss after mini-batch  1120: 4.014518\n",
      "Loss after mini-batch  1130: 4.385437\n",
      "Loss after mini-batch  1140: 4.042997\n",
      "Loss after mini-batch  1150: 4.077473\n",
      "Loss after mini-batch  1160: 3.982865\n",
      "Loss after mini-batch  1170: 4.180741\n",
      "Loss after mini-batch  1180: 3.959729\n",
      "Loss after mini-batch  1190: 3.988441\n",
      "Loss after mini-batch  1200: 3.955550\n",
      "Loss after mini-batch  1210: 4.242841\n",
      "Loss after mini-batch  1220: 4.278329\n",
      "Average Train Loss: 267.98249471073757\n",
      "SCORE IS: 0.2815199116387993\n",
      "Average validation Loss: 271.4373165435169\n",
      "TOP SCORE: 0.2815199116387993 ON EPOCH: 0\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 4.274801\n",
      "Loss after mini-batch    20: 4.126062\n",
      "Loss after mini-batch    30: 4.081072\n",
      "Loss after mini-batch    40: 3.914755\n",
      "Loss after mini-batch    50: 3.932778\n",
      "Loss after mini-batch    60: 3.812703\n",
      "Loss after mini-batch    70: 3.736287\n",
      "Loss after mini-batch    80: 3.538509\n",
      "Loss after mini-batch    90: 3.916932\n",
      "Loss after mini-batch   100: 4.181759\n",
      "Loss after mini-batch   110: 3.858686\n",
      "Loss after mini-batch   120: 3.689624\n",
      "Loss after mini-batch   130: 3.833178\n",
      "Loss after mini-batch   140: 4.004659\n",
      "Loss after mini-batch   150: 4.081007\n",
      "Loss after mini-batch   160: 3.743497\n",
      "Loss after mini-batch   170: 4.077536\n",
      "Loss after mini-batch   180: 3.997137\n",
      "Loss after mini-batch   190: 4.270151\n",
      "Loss after mini-batch   200: 4.015574\n",
      "Loss after mini-batch   210: 4.285460\n",
      "Loss after mini-batch   220: 3.656456\n",
      "Loss after mini-batch   230: 4.077796\n",
      "Loss after mini-batch   240: 3.751620\n",
      "Loss after mini-batch   250: 4.168934\n",
      "Loss after mini-batch   260: 3.627761\n",
      "Loss after mini-batch   270: 4.226554\n",
      "Loss after mini-batch   280: 4.132307\n",
      "Loss after mini-batch   290: 4.015437\n",
      "Loss after mini-batch   300: 4.446791\n",
      "Loss after mini-batch   310: 4.053184\n",
      "Loss after mini-batch   320: 3.743773\n",
      "Loss after mini-batch   330: 4.038869\n",
      "Loss after mini-batch   340: 3.919903\n",
      "Loss after mini-batch   350: 3.539939\n",
      "Loss after mini-batch   360: 4.247030\n",
      "Loss after mini-batch   370: 3.749224\n",
      "Loss after mini-batch   380: 3.913476\n",
      "Loss after mini-batch   390: 4.008806\n",
      "Loss after mini-batch   400: 3.788782\n",
      "Loss after mini-batch   410: 4.036441\n",
      "Loss after mini-batch   420: 3.988429\n",
      "Loss after mini-batch   430: 4.060924\n",
      "Loss after mini-batch   440: 3.435994\n",
      "Loss after mini-batch   450: 3.782160\n",
      "Loss after mini-batch   460: 4.028426\n",
      "Loss after mini-batch   470: 3.923266\n",
      "Loss after mini-batch   480: 4.481518\n",
      "Loss after mini-batch   490: 3.952192\n",
      "Loss after mini-batch   500: 3.956426\n",
      "Loss after mini-batch   510: 4.107640\n",
      "Loss after mini-batch   520: 3.979484\n",
      "Loss after mini-batch   530: 4.119579\n",
      "Loss after mini-batch   540: 3.677025\n",
      "Loss after mini-batch   550: 4.195459\n",
      "Loss after mini-batch   560: 4.372221\n",
      "Loss after mini-batch   570: 4.446401\n",
      "Loss after mini-batch   580: 4.531898\n",
      "Loss after mini-batch   590: 4.267324\n",
      "Loss after mini-batch   600: 4.125043\n",
      "Loss after mini-batch   610: 4.274362\n",
      "Loss after mini-batch   620: 3.777145\n",
      "Loss after mini-batch   630: 4.313121\n",
      "Loss after mini-batch   640: 4.069503\n",
      "Loss after mini-batch   650: 4.373610\n",
      "Loss after mini-batch   660: 3.956955\n",
      "Loss after mini-batch   670: 4.031698\n",
      "Loss after mini-batch   680: 4.153845\n",
      "Loss after mini-batch   690: 4.497295\n",
      "Loss after mini-batch   700: 3.916312\n",
      "Loss after mini-batch   710: 3.835751\n",
      "Loss after mini-batch   720: 4.139363\n",
      "Loss after mini-batch   730: 4.299932\n",
      "Loss after mini-batch   740: 4.177665\n",
      "Loss after mini-batch   750: 3.829302\n",
      "Loss after mini-batch   760: 3.797379\n",
      "Loss after mini-batch   770: 3.926532\n",
      "Loss after mini-batch   780: 3.723978\n",
      "Loss after mini-batch   790: 3.663029\n",
      "Loss after mini-batch   800: 4.260011\n",
      "Loss after mini-batch   810: 3.842133\n",
      "Loss after mini-batch   820: 4.216481\n",
      "Loss after mini-batch   830: 3.613047\n",
      "Loss after mini-batch   840: 4.087848\n",
      "Loss after mini-batch   850: 3.791644\n",
      "Loss after mini-batch   860: 3.863133\n",
      "Loss after mini-batch   870: 4.247230\n",
      "Loss after mini-batch   880: 3.892894\n",
      "Loss after mini-batch   890: 4.493032\n",
      "Loss after mini-batch   900: 3.804070\n",
      "Loss after mini-batch   910: 3.791796\n",
      "Loss after mini-batch   920: 3.867731\n",
      "Loss after mini-batch   930: 4.131391\n",
      "Loss after mini-batch   940: 3.768178\n",
      "Loss after mini-batch   950: 3.930264\n",
      "Loss after mini-batch   960: 3.973033\n",
      "Loss after mini-batch   970: 4.412742\n",
      "Loss after mini-batch   980: 4.302391\n",
      "Loss after mini-batch   990: 3.904386\n",
      "Loss after mini-batch  1000: 3.972806\n",
      "Loss after mini-batch  1010: 4.073192\n",
      "Loss after mini-batch  1020: 3.766660\n",
      "Loss after mini-batch  1030: 4.215266\n",
      "Loss after mini-batch  1040: 4.080712\n",
      "Loss after mini-batch  1050: 4.141786\n",
      "Loss after mini-batch  1060: 4.730206\n",
      "Loss after mini-batch  1070: 3.984544\n",
      "Loss after mini-batch  1080: 3.794936\n",
      "Loss after mini-batch  1090: 4.314421\n",
      "Loss after mini-batch  1100: 3.857832\n",
      "Loss after mini-batch  1110: 4.283052\n",
      "Loss after mini-batch  1120: 3.964168\n",
      "Loss after mini-batch  1130: 3.914992\n",
      "Loss after mini-batch  1140: 4.105658\n",
      "Loss after mini-batch  1150: 4.310989\n",
      "Loss after mini-batch  1160: 3.684558\n",
      "Loss after mini-batch  1170: 4.005182\n",
      "Loss after mini-batch  1180: 3.496540\n",
      "Loss after mini-batch  1190: 3.598282\n",
      "Loss after mini-batch  1200: 4.140516\n",
      "Loss after mini-batch  1210: 4.038494\n",
      "Loss after mini-batch  1220: 3.800297\n",
      "Average Train Loss: 256.6147962443976\n",
      "SCORE IS: 0.2939192759814043\n",
      "Average validation Loss: 266.5548515875931\n",
      "TOP SCORE: 0.2939192759814043 ON EPOCH: 1\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 3.691963\n",
      "Loss after mini-batch    20: 3.930645\n",
      "Loss after mini-batch    30: 4.243782\n",
      "Loss after mini-batch    40: 3.881594\n",
      "Loss after mini-batch    50: 4.027622\n",
      "Loss after mini-batch    60: 3.696915\n",
      "Loss after mini-batch    70: 3.708125\n",
      "Loss after mini-batch    80: 4.299126\n",
      "Loss after mini-batch    90: 4.127135\n",
      "Loss after mini-batch   100: 3.761829\n",
      "Loss after mini-batch   110: 3.793078\n",
      "Loss after mini-batch   120: 3.882013\n",
      "Loss after mini-batch   130: 3.312093\n",
      "Loss after mini-batch   140: 4.304946\n",
      "Loss after mini-batch   150: 3.886946\n",
      "Loss after mini-batch   160: 3.712760\n",
      "Loss after mini-batch   170: 3.839009\n",
      "Loss after mini-batch   180: 3.592615\n",
      "Loss after mini-batch   190: 4.057073\n",
      "Loss after mini-batch   200: 4.029985\n",
      "Loss after mini-batch   210: 3.707723\n",
      "Loss after mini-batch   220: 3.859251\n",
      "Loss after mini-batch   230: 3.584362\n",
      "Loss after mini-batch   240: 3.853736\n",
      "Loss after mini-batch   250: 4.095871\n",
      "Loss after mini-batch   260: 3.528880\n",
      "Loss after mini-batch   270: 3.994300\n",
      "Loss after mini-batch   280: 3.580404\n",
      "Loss after mini-batch   290: 3.752507\n",
      "Loss after mini-batch   300: 3.831516\n",
      "Loss after mini-batch   310: 3.862263\n",
      "Loss after mini-batch   320: 3.552850\n",
      "Loss after mini-batch   330: 4.532176\n",
      "Loss after mini-batch   340: 3.660791\n",
      "Loss after mini-batch   350: 3.853516\n",
      "Loss after mini-batch   360: 3.864909\n",
      "Loss after mini-batch   370: 4.022112\n",
      "Loss after mini-batch   380: 3.881486\n",
      "Loss after mini-batch   390: 4.412699\n",
      "Loss after mini-batch   400: 3.827506\n",
      "Loss after mini-batch   410: 4.143982\n",
      "Loss after mini-batch   420: 4.091256\n",
      "Loss after mini-batch   430: 4.041597\n",
      "Loss after mini-batch   440: 4.303095\n",
      "Loss after mini-batch   450: 3.917613\n",
      "Loss after mini-batch   460: 3.803365\n",
      "Loss after mini-batch   470: 4.492040\n",
      "Loss after mini-batch   480: 4.005716\n",
      "Loss after mini-batch   490: 4.185071\n",
      "Loss after mini-batch   500: 4.010975\n",
      "Loss after mini-batch   510: 3.650001\n",
      "Loss after mini-batch   520: 3.935725\n",
      "Loss after mini-batch   530: 4.191131\n",
      "Loss after mini-batch   540: 4.287695\n",
      "Loss after mini-batch   550: 3.873175\n",
      "Loss after mini-batch   560: 3.997160\n",
      "Loss after mini-batch   570: 3.747332\n",
      "Loss after mini-batch   580: 4.257305\n",
      "Loss after mini-batch   590: 4.124780\n",
      "Loss after mini-batch   600: 3.884708\n",
      "Loss after mini-batch   610: 3.708068\n",
      "Loss after mini-batch   620: 3.966981\n",
      "Loss after mini-batch   630: 4.034094\n",
      "Loss after mini-batch   640: 4.346485\n",
      "Loss after mini-batch   650: 3.849062\n",
      "Loss after mini-batch   660: 3.927033\n",
      "Loss after mini-batch   670: 3.870772\n",
      "Loss after mini-batch   680: 3.910684\n",
      "Loss after mini-batch   690: 3.656262\n",
      "Loss after mini-batch   700: 3.853668\n",
      "Loss after mini-batch   710: 3.571747\n",
      "Loss after mini-batch   720: 3.716071\n",
      "Loss after mini-batch   730: 4.345658\n",
      "Loss after mini-batch   740: 3.780489\n",
      "Loss after mini-batch   750: 3.627719\n",
      "Loss after mini-batch   760: 4.014795\n",
      "Loss after mini-batch   770: 3.770726\n",
      "Loss after mini-batch   780: 3.665423\n",
      "Loss after mini-batch   790: 3.886992\n",
      "Loss after mini-batch   800: 3.814276\n",
      "Loss after mini-batch   810: 3.940286\n",
      "Loss after mini-batch   820: 3.972679\n",
      "Loss after mini-batch   830: 4.002963\n",
      "Loss after mini-batch   840: 3.875331\n",
      "Loss after mini-batch   850: 3.801417\n",
      "Loss after mini-batch   860: 3.685759\n",
      "Loss after mini-batch   870: 3.304687\n",
      "Loss after mini-batch   880: 3.996524\n",
      "Loss after mini-batch   890: 3.940738\n",
      "Loss after mini-batch   900: 4.033347\n",
      "Loss after mini-batch   910: 3.715781\n",
      "Loss after mini-batch   920: 3.922507\n",
      "Loss after mini-batch   930: 3.964940\n",
      "Loss after mini-batch   940: 4.588190\n",
      "Loss after mini-batch   950: 3.788158\n",
      "Loss after mini-batch   960: 3.746752\n",
      "Loss after mini-batch   970: 3.939510\n",
      "Loss after mini-batch   980: 3.623507\n",
      "Loss after mini-batch   990: 3.890030\n",
      "Loss after mini-batch  1000: 3.823247\n",
      "Loss after mini-batch  1010: 3.735066\n",
      "Loss after mini-batch  1020: 3.663839\n",
      "Loss after mini-batch  1030: 4.010908\n",
      "Loss after mini-batch  1040: 3.341499\n",
      "Loss after mini-batch  1050: 3.757838\n",
      "Loss after mini-batch  1060: 3.865436\n",
      "Loss after mini-batch  1070: 3.377556\n",
      "Loss after mini-batch  1080: 3.613207\n",
      "Loss after mini-batch  1090: 3.530664\n",
      "Loss after mini-batch  1100: 3.042731\n",
      "Loss after mini-batch  1110: 3.695166\n",
      "Loss after mini-batch  1120: 3.490317\n",
      "Loss after mini-batch  1130: 3.464002\n",
      "Loss after mini-batch  1140: 3.489739\n",
      "Loss after mini-batch  1150: 3.609490\n",
      "Loss after mini-batch  1160: 3.862561\n",
      "Loss after mini-batch  1170: 3.661231\n",
      "Loss after mini-batch  1180: 3.290302\n",
      "Loss after mini-batch  1190: 3.588784\n",
      "Loss after mini-batch  1200: 3.566627\n",
      "Loss after mini-batch  1210: 4.139676\n",
      "Loss after mini-batch  1220: 3.739280\n",
      "Average Train Loss: 246.76255216023478\n",
      "SCORE IS: 0.29658438931057546\n",
      "Average validation Loss: 266.7599656273109\n",
      "TOP SCORE: 0.29658438931057546 ON EPOCH: 2\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 4.241385\n",
      "Loss after mini-batch    20: 3.512888\n",
      "Loss after mini-batch    30: 3.521362\n",
      "Loss after mini-batch    40: 3.922487\n",
      "Loss after mini-batch    50: 3.936061\n",
      "Loss after mini-batch    60: 3.878965\n",
      "Loss after mini-batch    70: 4.045224\n",
      "Loss after mini-batch    80: 3.376220\n",
      "Loss after mini-batch    90: 3.814458\n",
      "Loss after mini-batch   100: 4.159180\n",
      "Loss after mini-batch   110: 3.515315\n",
      "Loss after mini-batch   120: 3.865243\n",
      "Loss after mini-batch   130: 3.939802\n",
      "Loss after mini-batch   140: 3.858467\n",
      "Loss after mini-batch   150: 3.505347\n",
      "Loss after mini-batch   160: 3.761004\n",
      "Loss after mini-batch   170: 3.962080\n",
      "Loss after mini-batch   180: 3.771534\n",
      "Loss after mini-batch   190: 3.928367\n",
      "Loss after mini-batch   200: 3.695852\n",
      "Loss after mini-batch   210: 3.677803\n",
      "Loss after mini-batch   220: 3.618171\n",
      "Loss after mini-batch   230: 3.793421\n",
      "Loss after mini-batch   240: 4.004743\n",
      "Loss after mini-batch   250: 3.589772\n",
      "Loss after mini-batch   260: 3.807363\n",
      "Loss after mini-batch   270: 3.672454\n",
      "Loss after mini-batch   280: 3.699337\n",
      "Loss after mini-batch   290: 3.418928\n",
      "Loss after mini-batch   300: 3.460393\n",
      "Loss after mini-batch   310: 3.972984\n",
      "Loss after mini-batch   320: 4.017664\n",
      "Loss after mini-batch   330: 3.890275\n",
      "Loss after mini-batch   340: 3.829001\n",
      "Loss after mini-batch   350: 3.586362\n",
      "Loss after mini-batch   360: 3.361416\n",
      "Loss after mini-batch   370: 3.608242\n",
      "Loss after mini-batch   380: 3.394493\n",
      "Loss after mini-batch   390: 3.933951\n",
      "Loss after mini-batch   400: 3.974050\n",
      "Loss after mini-batch   410: 4.163676\n",
      "Loss after mini-batch   420: 3.738465\n",
      "Loss after mini-batch   430: 4.238278\n",
      "Loss after mini-batch   440: 4.169264\n",
      "Loss after mini-batch   450: 3.381634\n",
      "Loss after mini-batch   460: 3.745721\n",
      "Loss after mini-batch   470: 4.033041\n",
      "Loss after mini-batch   480: 3.649586\n",
      "Loss after mini-batch   490: 3.889429\n",
      "Loss after mini-batch   500: 3.452615\n",
      "Loss after mini-batch   510: 3.703722\n",
      "Loss after mini-batch   520: 3.310212\n",
      "Loss after mini-batch   530: 3.614491\n",
      "Loss after mini-batch   540: 3.869588\n",
      "Loss after mini-batch   550: 3.864195\n",
      "Loss after mini-batch   560: 3.481318\n",
      "Loss after mini-batch   570: 4.331277\n",
      "Loss after mini-batch   580: 3.471029\n",
      "Loss after mini-batch   590: 3.888536\n",
      "Loss after mini-batch   600: 3.693033\n",
      "Loss after mini-batch   610: 3.823707\n",
      "Loss after mini-batch   620: 3.674247\n",
      "Loss after mini-batch   630: 3.347398\n",
      "Loss after mini-batch   640: 3.722402\n",
      "Loss after mini-batch   650: 3.624714\n",
      "Loss after mini-batch   660: 3.634317\n",
      "Loss after mini-batch   670: 3.559507\n",
      "Loss after mini-batch   680: 3.406016\n",
      "Loss after mini-batch   690: 3.736657\n",
      "Loss after mini-batch   700: 3.295374\n",
      "Loss after mini-batch   710: 3.595060\n",
      "Loss after mini-batch   720: 3.493655\n",
      "Loss after mini-batch   730: 3.650664\n",
      "Loss after mini-batch   740: 3.685703\n",
      "Loss after mini-batch   750: 3.626138\n",
      "Loss after mini-batch   760: 3.492766\n",
      "Loss after mini-batch   770: 3.935124\n",
      "Loss after mini-batch   780: 4.164750\n",
      "Loss after mini-batch   790: 3.884717\n",
      "Loss after mini-batch   800: 3.616965\n",
      "Loss after mini-batch   810: 3.408178\n",
      "Loss after mini-batch   820: 3.740155\n",
      "Loss after mini-batch   830: 3.899090\n",
      "Loss after mini-batch   840: 3.884288\n",
      "Loss after mini-batch   850: 3.630784\n",
      "Loss after mini-batch   860: 3.750818\n",
      "Loss after mini-batch   870: 3.458394\n",
      "Loss after mini-batch   880: 4.027186\n",
      "Loss after mini-batch   890: 3.721898\n",
      "Loss after mini-batch   900: 3.411756\n",
      "Loss after mini-batch   910: 3.883039\n",
      "Loss after mini-batch   920: 3.135624\n",
      "Loss after mini-batch   930: 3.866765\n",
      "Loss after mini-batch   940: 3.744915\n",
      "Loss after mini-batch   950: 3.614427\n",
      "Loss after mini-batch   960: 3.690135\n",
      "Loss after mini-batch   970: 3.677179\n",
      "Loss after mini-batch   980: 3.724394\n",
      "Loss after mini-batch   990: 3.491018\n",
      "Loss after mini-batch  1000: 3.531885\n",
      "Loss after mini-batch  1010: 3.678154\n",
      "Loss after mini-batch  1020: 3.317950\n",
      "Loss after mini-batch  1030: 3.781193\n",
      "Loss after mini-batch  1040: 3.460711\n",
      "Loss after mini-batch  1050: 3.826578\n",
      "Loss after mini-batch  1060: 3.354755\n",
      "Loss after mini-batch  1070: 3.291576\n",
      "Loss after mini-batch  1080: 3.571034\n",
      "Loss after mini-batch  1090: 3.183978\n",
      "Loss after mini-batch  1100: 3.612627\n",
      "Loss after mini-batch  1110: 3.478481\n",
      "Loss after mini-batch  1120: 3.672337\n",
      "Loss after mini-batch  1130: 3.749122\n",
      "Loss after mini-batch  1140: 3.963516\n",
      "Loss after mini-batch  1150: 3.155558\n",
      "Loss after mini-batch  1160: 3.741502\n",
      "Loss after mini-batch  1170: 3.460425\n",
      "Loss after mini-batch  1180: 3.441448\n",
      "Loss after mini-batch  1190: 3.479689\n",
      "Loss after mini-batch  1200: 3.680483\n",
      "Loss after mini-batch  1210: 4.053470\n",
      "Loss after mini-batch  1220: 3.546639\n",
      "Average Train Loss: 236.576634722923\n",
      "SCORE IS: 0.27664045676221466\n",
      "Average validation Loss: 268.3665339925075\n",
      "TOP SCORE: 0.29658438931057546 ON EPOCH: 2\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 3.897723\n",
      "Loss after mini-batch    20: 3.197026\n",
      "Loss after mini-batch    30: 4.074160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate over the DataLoader for training data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m   \u001b[38;5;66;03m# Get and prepare inputs\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   inputs, image, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     19\u001b[0m   inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat(), targets\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:348\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     29\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids[i]]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom:\n\u001b[0;32m---> 31\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:105\u001b[0m, in \u001b[0;36mRandomApply.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m--> 105\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:172\u001b[0m, in \u001b[0;36mRandomOrder.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms)):\n\u001b[1;32m    171\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms[idx]\n\u001b[0;32m--> 172\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_auto_augment.py:495\u001b[0m, in \u001b[0;36mTrivialAugmentWide.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 495\u001b[0m image_or_video \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_image_or_video_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_or_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmagnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unflatten_and_insert_image_or_video(flat_inputs_with_spec, image_or_video)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_auto_augment.py:167\u001b[0m, in \u001b[0;36m_AutoAugmentBase._apply_image_or_video_transform\u001b[0;34m(self, image, transform_id, magnitude, interpolation, fill)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msolarize(image, threshold\u001b[38;5;241m=\u001b[39mbound \u001b[38;5;241m*\u001b[39m magnitude)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m transform_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoContrast\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocontrast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m transform_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEqualize\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mequalize(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/functional/_color.py:519\u001b[0m, in \u001b[0;36mautocontrast\u001b[0;34m(inpt)\u001b[0m\n\u001b[1;32m    516\u001b[0m _log_api_usage_once(autocontrast)\n\u001b[1;32m    518\u001b[0m kernel \u001b[38;5;241m=\u001b[39m _get_kernel(autocontrast, \u001b[38;5;28mtype\u001b[39m(inpt))\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:386\u001b[0m, in \u001b[0;36mautocontrast\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pil_image(img):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImageOps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocontrast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageOps.py:162\u001b[0m, in \u001b[0;36mautocontrast\u001b[0;34m(image, cutoff, ignore, mask, preserve_tone)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m    161\u001b[0m             lut\u001b[38;5;241m.\u001b[39mappend(ix)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlut\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageOps.py:59\u001b[0m, in \u001b[0;36m_lut\u001b[0;34m(image, lut)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lut) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m256\u001b[39m:\n\u001b[1;32m     58\u001b[0m         lut \u001b[38;5;241m=\u001b[39m lut \u001b[38;5;241m+\u001b[39m lut \u001b[38;5;241m+\u001b[39m lut\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlut\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot supported for mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:1861\u001b[0m, in \u001b[0;36mImage.point\u001b[0;34m(self, lut, mode)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1860\u001b[0m     lut \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mround\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m lut]\n\u001b[0;32m-> 1861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "checkpoints = []\n",
    "top_score = -100000000000.00\n",
    "top_epoch = -1\n",
    "for epoch in range(0, 100): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    model.train()\n",
    "    print(f'Starting epoch {epoch + 1}')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "    \n",
    "      # Get and prepare inputs\n",
    "      inputs, image, targets = data\n",
    "      inputs, targets = inputs.float(), targets.float()\n",
    "      targets = targets.reshape((targets.shape[0], 6))\n",
    "    \n",
    "      # Zero the gradients\n",
    "      optimizer.zero_grad()\n",
    "    \n",
    "      # Perform forward pass\n",
    "      #outputs = vgg11(image.cuda(), inputs.cuda())\n",
    "      outputs = model(image.cuda(), inputs.cuda())\n",
    "      #outputs = mlp(inputs)\n",
    "      #print(CalculateR2(outputs, targets, Y_means.cuda()))\n",
    "    \n",
    "      # Compute loss\n",
    "      loss = loss_function(outputs, targets.cuda())\n",
    "    \n",
    "      # Perform backward pass\n",
    "      loss.backward()\n",
    "      clip = 5\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "      # Perform optimization\n",
    "      optimizer.step()\n",
    "    \n",
    "      # Print statistics\n",
    "      current_loss += loss.item()\n",
    "      total_loss += loss.item()\n",
    "      if i % 10 == 9:\n",
    "          print('Loss after mini-batch %5d: %f' %\n",
    "                (i + 1, current_loss / (batchsize * 10)))\n",
    "          current_loss = 0.0\n",
    "    print (f\"Average Train Loss: {total_loss / len(trainloader) / batchsize}\")\n",
    "    model.eval()\n",
    "    score = 0\n",
    "    total_loss = 0.0\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        inputs, image, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 6))\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image.cuda(), inputs.cuda())\n",
    "            #score += CalculateR2(torch.exp(outputs), torch.exp(targets.cuda()), Y_means.cuda())\n",
    "            total_loss += loss_function(outputs, targets.cuda())\n",
    "            score += CalculateR2(outputs, targets.cuda(), Y_means)\n",
    "    print(f\"SCORE IS: {score / len(valloader)}\")\n",
    "    print(f\"Average validation Loss: {total_loss / len(valloader) / batchsize}\")\n",
    "    score = score / len(valloader)\n",
    "    if score > top_score:\n",
    "        top_score = score\n",
    "        top_epoch = epoch\n",
    "    print(f\"TOP SCORE: {top_score} ON EPOCH: {top_epoch}\")\n",
    "\n",
    "    torch.save(model, 'temp_convnext.plt')\n",
    "    checkpoints.append(torch.load('temp_convnext.plt'))\n",
    "    \n",
    "    if (epoch % 10 == 9 or epoch % 10 == 4):\n",
    "        results = [['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']]\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, image, ids = data\n",
    "            if i % 1000 == 0:\n",
    "                print(i/6391)\n",
    "            inputs = inputs.float()\n",
    "            with torch.no_grad():\n",
    "                #outputs = torch.exp(vgg11(image.cuda(), inputs.cuda()))\n",
    "                #outputs = torch.exp(model(image.cuda(), inputs.cuda()))\n",
    "                outputs = model(image.cuda(), inputs.cuda())\n",
    "                #outputs = mlp(inputs)\n",
    "                results.append(ids.tolist() + outputs[0].tolist())\n",
    "        \n",
    "        with open(f\"results_convnext_full_autoaug_epoch{epoch + 1}.csv\",\"w\") as my_csv:\n",
    "            csvWriter = csv.writer(my_csv, delimiter=',')\n",
    "            csvWriter.writerows(results)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2bf540-f6a3-4d0c-be8e-d49b8710355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: 0.29658438931057546 BEST_EPOCH: 2\n",
      "0.0\n",
      "0.15647003598810827\n",
      "0.31294007197621654\n",
      "0.4694101079643248\n",
      "0.6258801439524331\n",
      "0.7823501799405413\n",
      "0.9388202159286496\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEST SCORE: {top_score} BEST_EPOCH: {top_epoch}\")\n",
    "results = [['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']]\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, image, ids = data\n",
    "    if i % 1000 == 0:\n",
    "        print(i/6391)\n",
    "    inputs = inputs.float()\n",
    "    with torch.no_grad():\n",
    "        #outputs = torch.exp(model(image.cuda(), inputs.cuda()))\n",
    "        outputs = checkpoints[top_epoch](image.cuda(), inputs.cuda())\n",
    "        #outputs = mlp(inputs)\n",
    "        results.append(ids.tolist() + outputs[0].tolist())\n",
    "\n",
    "with open(\"results_convnext_learningrate_best.csv\",\"w\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv, delimiter=',')\n",
    "    csvWriter.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbba89-a775-4a68-8877-b11e058fa1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
